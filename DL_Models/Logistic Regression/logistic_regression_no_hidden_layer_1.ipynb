{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#load data. labels are in one-hot-encoding format\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "\n",
    "\n",
    "# (Global) Parameters\n",
    "learning_rate = 0.05\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    #takes a batch of pictures as input and returns a batch of corresponding probabilities of being in each class\n",
    "    #input shape = (batch_size*image_size)     output shape = (batch_size*number_of_classes)\n",
    "    \n",
    "    init = tf.constant_initializer(value=0)\n",
    "\n",
    "    W = tf.get_variable(\"Weight\", [784, 10], initializer=init)\n",
    "    b = tf.get_variable(\"bias\", [10], initializer=init)\n",
    "\n",
    "    #This function performs the equivalent of softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "    #which returns a tensor with the same size as logits, the shape is batch_size*10 in this case \n",
    "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    # output and y have the same shape: batch_size * num_of_classes while the returned loss is a scaler tensor\n",
    "    # compute the average error per data sample by computing the cross-entropy loss over a minibatch\n",
    "    \n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    \n",
    "    #cross-entropy loss is more commonly used \n",
    "    #since the confidence of classification is taken into account\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the optimizer and training target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    \n",
    "    # learning_rate \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    # Global_step refers to the number of batches seen of far. \n",
    "    # When it is passed in the minimize() argument list, the variable is increased by one.\n",
    "    # You can get the global_step value using tf.train.global_step()\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    # correct_prediction is a vector of boolean elements\n",
    "    # where \n",
    "    # true denotes prediction equals to the real value \n",
    "    # and \n",
    "    # false means the opposite\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    #tf.cast transfer boolean tensor into float tensor\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.train.num_examples  55000\n",
      "mnist.test.num_examples  10000\n",
      "Epoch: 001 cost function= 0.6601918  Validation Error: 0.10979998111724854\n",
      "Epoch: 002 cost function= 0.4087275  Validation Error: 0.09920001029968262\n",
      "Epoch: 003 cost function= 0.3679224  Validation Error: 0.09280002117156982\n",
      "Epoch: 004 cost function= 0.3466269  Validation Error: 0.09079998731613159\n",
      "Epoch: 005 cost function= 0.3335501  Validation Error: 0.08539998531341553\n",
      "Epoch: 006 cost function= 0.3237427  Validation Error: 0.08480000495910645\n",
      "Epoch: 007 cost function= 0.3164115  Validation Error: 0.0835999846458435\n",
      "Epoch: 008 cost function= 0.3106738  Validation Error: 0.07959997653961182\n",
      "Epoch: 009 cost function= 0.3058826  Validation Error: 0.08039999008178711\n",
      "Epoch: 010 cost function= 0.3017234  Validation Error: 0.07859998941421509\n",
      "Epoch: 011 cost function= 0.2983048  Validation Error: 0.078000009059906\n",
      "Epoch: 012 cost function= 0.2953584  Validation Error: 0.07740002870559692\n",
      "Epoch: 013 cost function= 0.2927301  Validation Error: 0.07740002870559692\n",
      "Epoch: 014 cost function= 0.2902789  Validation Error: 0.07599997520446777\n",
      "Epoch: 015 cost function= 0.2882559  Validation Error: 0.07440000772476196\n",
      "Epoch: 016 cost function= 0.2863116  Validation Error: 0.0756000280380249\n",
      "Epoch: 017 cost function= 0.2844586  Validation Error: 0.07520002126693726\n",
      "Epoch: 018 cost function= 0.2828525  Validation Error: 0.07639998197555542\n",
      "Epoch: 019 cost function= 0.2812372  Validation Error: 0.07520002126693726\n",
      "Epoch: 020 cost function= 0.2799391  Validation Error: 0.07539999485015869\n",
      "Epoch: 021 cost function= 0.2785737  Validation Error: 0.07499998807907104\n",
      "Epoch: 022 cost function= 0.2772986  Validation Error: 0.0745999813079834\n",
      "Epoch: 023 cost function= 0.2762839  Validation Error: 0.07380002737045288\n",
      "Epoch: 024 cost function= 0.2752228  Validation Error: 0.07660001516342163\n",
      "Epoch: 025 cost function= 0.2741360  Validation Error: 0.07480001449584961\n",
      "Epoch: 026 cost function= 0.2732698  Validation Error: 0.07380002737045288\n",
      "Epoch: 027 cost function= 0.2723839  Validation Error: 0.07419997453689575\n",
      "Epoch: 028 cost function= 0.2715162  Validation Error: 0.07340002059936523\n",
      "Epoch: 029 cost function= 0.2707460  Validation Error: 0.07440000772476196\n",
      "Epoch: 030 cost function= 0.2699831  Validation Error: 0.07359999418258667\n",
      "Epoch: 031 cost function= 0.2691467  Validation Error: 0.07440000772476196\n",
      "Epoch: 032 cost function= 0.2684252  Validation Error: 0.07340002059936523\n",
      "Epoch: 033 cost function= 0.2678012  Validation Error: 0.07319998741149902\n",
      "Epoch: 034 cost function= 0.2671919  Validation Error: 0.07319998741149902\n",
      "Epoch: 035 cost function= 0.2663945  Validation Error: 0.07380002737045288\n",
      "Epoch: 036 cost function= 0.2659487  Validation Error: 0.07300001382827759\n",
      "Epoch: 037 cost function= 0.2653874  Validation Error: 0.07359999418258667\n",
      "Epoch: 038 cost function= 0.2648008  Validation Error: 0.07200002670288086\n",
      "Epoch: 039 cost function= 0.2641620  Validation Error: 0.0722000002861023\n",
      "Epoch: 040 cost function= 0.2637181  Validation Error: 0.07239997386932373\n",
      "Epoch: 041 cost function= 0.2633637  Validation Error: 0.071399986743927\n",
      "Epoch: 042 cost function= 0.2627249  Validation Error: 0.07200002670288086\n",
      "Epoch: 043 cost function= 0.2622579  Validation Error: 0.07279998064041138\n",
      "Epoch: 044 cost function= 0.2618849  Validation Error: 0.07179999351501465\n",
      "Epoch: 045 cost function= 0.2615139  Validation Error: 0.07179999351501465\n",
      "Epoch: 046 cost function= 0.2609179  Validation Error: 0.07380002737045288\n",
      "Epoch: 047 cost function= 0.2605339  Validation Error: 0.07239997386932373\n",
      "Epoch: 048 cost function= 0.2600436  Validation Error: 0.07099997997283936\n",
      "Epoch: 049 cost function= 0.2597321  Validation Error: 0.07179999351501465\n",
      "Epoch: 050 cost function= 0.2594024  Validation Error: 0.07239997386932373\n",
      "Epoch: 051 cost function= 0.2589031  Validation Error: 0.07239997386932373\n",
      "Epoch: 052 cost function= 0.2586847  Validation Error: 0.0722000002861023\n",
      "Epoch: 053 cost function= 0.2582868  Validation Error: 0.07239997386932373\n",
      "Epoch: 054 cost function= 0.2578095  Validation Error: 0.07179999351501465\n",
      "Epoch: 055 cost function= 0.2576126  Validation Error: 0.07099997997283936\n",
      "Epoch: 056 cost function= 0.2573454  Validation Error: 0.0722000002861023\n",
      "Epoch: 057 cost function= 0.2569949  Validation Error: 0.07260000705718994\n",
      "Epoch: 058 cost function= 0.2566808  Validation Error: 0.07260000705718994\n",
      "Epoch: 059 cost function= 0.2563574  Validation Error: 0.07200002670288086\n",
      "Epoch: 060 cost function= 0.2560640  Validation Error: 0.07179999351501465\n",
      "Epoch: 061 cost function= 0.2556727  Validation Error: 0.07200002670288086\n",
      "Epoch: 062 cost function= 0.2554755  Validation Error: 0.071399986743927\n",
      "Epoch: 063 cost function= 0.2551924  Validation Error: 0.07160001993179321\n",
      "Epoch: 064 cost function= 0.2549990  Validation Error: 0.0722000002861023\n",
      "Epoch: 065 cost function= 0.2545371  Validation Error: 0.07160001993179321\n",
      "Epoch: 066 cost function= 0.2543984  Validation Error: 0.07099997997283936\n",
      "Epoch: 067 cost function= 0.2539140  Validation Error: 0.07160001993179321\n",
      "Epoch: 068 cost function= 0.2536829  Validation Error: 0.071399986743927\n",
      "Epoch: 069 cost function= 0.2534941  Validation Error: 0.071399986743927\n",
      "Epoch: 070 cost function= 0.2532874  Validation Error: 0.07200002670288086\n",
      "Epoch: 071 cost function= 0.2530486  Validation Error: 0.07120001316070557\n",
      "Epoch: 072 cost function= 0.2528151  Validation Error: 0.071399986743927\n",
      "Epoch: 073 cost function= 0.2525412  Validation Error: 0.06999999284744263\n",
      "Epoch: 074 cost function= 0.2522616  Validation Error: 0.07080000638961792\n",
      "Epoch: 075 cost function= 0.2522087  Validation Error: 0.07160001993179321\n",
      "Epoch: 076 cost function= 0.2519622  Validation Error: 0.07059997320175171\n",
      "Epoch: 077 cost function= 0.2516758  Validation Error: 0.07080000638961792\n",
      "Epoch: 078 cost function= 0.2514696  Validation Error: 0.07120001316070557\n",
      "Epoch: 079 cost function= 0.2513157  Validation Error: 0.07080000638961792\n",
      "Epoch: 080 cost function= 0.2509585  Validation Error: 0.07080000638961792\n",
      "Epoch: 081 cost function= 0.2508886  Validation Error: 0.071399986743927\n",
      "Epoch: 082 cost function= 0.2507448  Validation Error: 0.07120001316070557\n",
      "Epoch: 083 cost function= 0.2505503  Validation Error: 0.07099997997283936\n",
      "Epoch: 084 cost function= 0.2502869  Validation Error: 0.07179999351501465\n",
      "Epoch: 085 cost function= 0.2501382  Validation Error: 0.06940001249313354\n",
      "Epoch: 086 cost function= 0.2498666  Validation Error: 0.071399986743927\n",
      "Epoch: 087 cost function= 0.2496494  Validation Error: 0.071399986743927\n",
      "Epoch: 088 cost function= 0.2494862  Validation Error: 0.071399986743927\n",
      "Epoch: 089 cost function= 0.2492619  Validation Error: 0.07080000638961792\n",
      "Epoch: 090 cost function= 0.2491230  Validation Error: 0.07080000638961792\n",
      "Epoch: 091 cost function= 0.2488950  Validation Error: 0.07160001993179321\n",
      "Epoch: 092 cost function= 0.2489554  Validation Error: 0.07059997320175171\n",
      "Epoch: 093 cost function= 0.2485305  Validation Error: 0.06919997930526733\n",
      "Epoch: 094 cost function= 0.2484336  Validation Error: 0.07080000638961792\n",
      "Epoch: 095 cost function= 0.2482795  Validation Error: 0.07059997320175171\n",
      "Epoch: 096 cost function= 0.2481553  Validation Error: 0.07080000638961792\n",
      "Epoch: 097 cost function= 0.2480419  Validation Error: 0.071399986743927\n",
      "Epoch: 098 cost function= 0.2478208  Validation Error: 0.07120001316070557\n",
      "Epoch: 099 cost function= 0.2477003  Validation Error: 0.06980001926422119\n",
      "Epoch: 100 cost function= 0.2473825  Validation Error: 0.06999999284744263\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.9257\n",
      "Execution time was 85.379\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #change it with your own path\n",
    "    log_files_path = 'C:/Users/Ali/logs/no_layer_1/'\n",
    "    #log_files_path = 'C:/Users/Ali/Google Drive/CoursesColumbiaUniveristy/DeepLearning/codes/week3/logs/no_layer/'\n",
    "\n",
    "    # read \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/Graph\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "            \n",
    "        # first build the structure of our neural network\n",
    "\n",
    "        # variables has to be set up as placeholder before importing data\n",
    "        x = tf.placeholder(\"float\", [None, 784]) # MNIST data image of shape 28*28=784\n",
    "\n",
    "        # y is the label in one-hot-encoding format\n",
    "        y = tf.placeholder(\"float\", [None, 10])  # 0-9 digits recognition\n",
    "\n",
    "        #output is a matrix of probabilities\n",
    "        output = inference(x)\n",
    "\n",
    "        cost = loss(output, y)\n",
    "        # set the initial value of global_step as 0\n",
    "        # this will increase by 1 every time weights are updated\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        train_op = training(cost, global_step)\n",
    "        #train_op = training(cost, global_step=None)\n",
    "\n",
    "        eval_op = evaluate(output, y)\n",
    "\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "        saver = tf.train.Saver()\n",
    "        #define a session\n",
    "        sess = tf.Session()\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(log_files_path, sess.graph)\n",
    "\n",
    "        #all variables need to be initialized by sess.run(tf.global_variables_initializer())\n",
    "        init_op = tf.global_variables_initializer()\n",
    "\n",
    "        sess.run(init_op)\n",
    "\n",
    "        print('mnist.train.num_examples ', mnist.train.num_examples)\n",
    "        print('mnist.test.num_examples ', mnist.test.num_examples)\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            #print('total_batch ', total_batch)\n",
    "\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "\n",
    "                minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                \n",
    "                # Fit training using batch data\n",
    "                # Weights are only updated when we run the optimizer\n",
    "                sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                \n",
    "                # Compute average loss\n",
    "                avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "\n",
    "            # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "                \n",
    "                # Get the accuracy by running the eval_op with validation sets of data\n",
    "                accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "\n",
    "                print(\"Epoch:\", '%03d' % (epoch+1), \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "\n",
    "                summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "\n",
    "                #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Check the final accuracy after training\n",
    "        accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print('Execution time was %0.3f' % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
