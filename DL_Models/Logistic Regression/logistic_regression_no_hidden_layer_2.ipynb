{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#load data. labels are in one-hot-encoding format\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "\n",
    "\n",
    "# (Global) Parameters\n",
    "learning_rate = 0.0005\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    #takes a batch of pictures as input and returns a batch of corresponding probabilities of being in each class\n",
    "    #input shape = (batch_size*image_size)     output shape = (batch_size*number_of_classes)\n",
    "    \n",
    "    init = tf.constant_initializer(value=0)\n",
    "\n",
    "    W = tf.get_variable(\"Weight\", [784, 10], initializer=init)\n",
    "    b = tf.get_variable(\"bias\", [10], initializer=init)\n",
    "\n",
    "    #This function performs the equivalent of softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "    #which returns a tensor with the same size as logits, the shape is batch_size*10 in this case \n",
    "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    # output and y have the same shape: batch_size * num_of_classes while the returned loss is a scaler tensor\n",
    "    # compute the average error per data sample by computing the cross-entropy loss over a minibatch\n",
    "    \n",
    "    #mean square error\n",
    "    #loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-output)))\n",
    "    \n",
    "    \n",
    "    #cross-entropy loss is more commonly used \n",
    "    #since the confidence of classification is taken into account\n",
    "    dot_product = y * tf.log(output)\n",
    "    \n",
    "    #tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.\n",
    "    xentropy = -tf.reduce_sum(dot_product, 1)\n",
    "    \n",
    "    #tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the optimizer and training target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    \n",
    "    # learning_rate \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "    \n",
    "    # Global_step refers to the number of batches seen of far. \n",
    "    # When it is passed in the minimize() argument list, the variable is increased by one.\n",
    "    # You can get the global_step value using tf.train.global_step()\n",
    "    \n",
    "\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    # correct_prediction is a vector of boolean elements\n",
    "    # where \n",
    "    # true denotes prediction equals to the real value \n",
    "    # and \n",
    "    # false means the opposite\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    #tf.cast transfer boolean tensor into float tensor\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.train.num_examples  55000\n",
      "mnist.test.num_examples  10000\n",
      "Epoch: 001 cost function= 0.8448279  Validation Error: 0.11040002107620239\n",
      "Epoch: 002 cost function= 0.4283471  Validation Error: 0.09399998188018799\n",
      "Epoch: 003 cost function= 0.3621549  Validation Error: 0.08740001916885376\n",
      "Epoch: 004 cost function= 0.3316875  Validation Error: 0.08420002460479736\n",
      "Epoch: 005 cost function= 0.3139974  Validation Error: 0.08060002326965332\n",
      "Epoch: 006 cost function= 0.3018381  Validation Error: 0.07940000295639038\n",
      "Epoch: 007 cost function= 0.2933800  Validation Error: 0.0777999758720398\n",
      "Epoch: 008 cost function= 0.2870633  Validation Error: 0.07520002126693726\n",
      "Epoch: 009 cost function= 0.2816436  Validation Error: 0.07620000839233398\n",
      "Epoch: 010 cost function= 0.2772597  Validation Error: 0.07400000095367432\n",
      "Epoch: 011 cost function= 0.2739142  Validation Error: 0.0745999813079834\n",
      "Epoch: 012 cost function= 0.2707763  Validation Error: 0.07340002059936523\n",
      "Epoch: 013 cost function= 0.2680086  Validation Error: 0.07319998741149902\n",
      "Epoch: 014 cost function= 0.2656671  Validation Error: 0.07260000705718994\n",
      "Epoch: 015 cost function= 0.2636705  Validation Error: 0.07239997386932373\n",
      "Epoch: 016 cost function= 0.2617857  Validation Error: 0.07099997997283936\n",
      "Epoch: 017 cost function= 0.2597710  Validation Error: 0.07300001382827759\n",
      "Epoch: 018 cost function= 0.2583951  Validation Error: 0.07400000095367432\n",
      "Epoch: 019 cost function= 0.2571849  Validation Error: 0.07200002670288086\n",
      "Epoch: 020 cost function= 0.2557484  Validation Error: 0.0722000002861023\n",
      "Epoch: 021 cost function= 0.2546541  Validation Error: 0.07200002670288086\n",
      "Epoch: 022 cost function= 0.2535253  Validation Error: 0.07039999961853027\n",
      "Epoch: 023 cost function= 0.2522979  Validation Error: 0.06999999284744263\n",
      "Epoch: 024 cost function= 0.2514616  Validation Error: 0.07179999351501465\n",
      "Epoch: 025 cost function= 0.2504423  Validation Error: 0.07120001316070557\n",
      "Epoch: 026 cost function= 0.2495088  Validation Error: 0.07099997997283936\n",
      "Epoch: 027 cost function= 0.2487670  Validation Error: 0.07179999351501465\n",
      "Epoch: 028 cost function= 0.2479499  Validation Error: 0.06980001926422119\n",
      "Epoch: 029 cost function= 0.2472690  Validation Error: 0.071399986743927\n",
      "Epoch: 030 cost function= 0.2466313  Validation Error: 0.06919997930526733\n",
      "Epoch: 031 cost function= 0.2459487  Validation Error: 0.07179999351501465\n",
      "Epoch: 032 cost function= 0.2450637  Validation Error: 0.07039999961853027\n",
      "Epoch: 033 cost function= 0.2445941  Validation Error: 0.07080000638961792\n",
      "Epoch: 034 cost function= 0.2440101  Validation Error: 0.06840002536773682\n",
      "Epoch: 035 cost function= 0.2433845  Validation Error: 0.06879997253417969\n",
      "Epoch: 036 cost function= 0.2429179  Validation Error: 0.06840002536773682\n",
      "Epoch: 037 cost function= 0.2424685  Validation Error: 0.06879997253417969\n",
      "Epoch: 038 cost function= 0.2418710  Validation Error: 0.06980001926422119\n",
      "Epoch: 039 cost function= 0.2413011  Validation Error: 0.07039999961853027\n",
      "Epoch: 040 cost function= 0.2410145  Validation Error: 0.07039999961853027\n",
      "Epoch: 041 cost function= 0.2404270  Validation Error: 0.06859999895095825\n",
      "Epoch: 042 cost function= 0.2400717  Validation Error: 0.07160001993179321\n",
      "Epoch: 043 cost function= 0.2396698  Validation Error: 0.07160001993179321\n",
      "Epoch: 044 cost function= 0.2389759  Validation Error: 0.06879997253417969\n",
      "Epoch: 045 cost function= 0.2388242  Validation Error: 0.071399986743927\n",
      "Epoch: 046 cost function= 0.2385041  Validation Error: 0.07080000638961792\n",
      "Epoch: 047 cost function= 0.2380459  Validation Error: 0.071399986743927\n",
      "Epoch: 048 cost function= 0.2375788  Validation Error: 0.07059997320175171\n",
      "Epoch: 049 cost function= 0.2371741  Validation Error: 0.06840002536773682\n",
      "Epoch: 050 cost function= 0.2369842  Validation Error: 0.06940001249313354\n",
      "Epoch: 051 cost function= 0.2366496  Validation Error: 0.06980001926422119\n",
      "Epoch: 052 cost function= 0.2361619  Validation Error: 0.0690000057220459\n",
      "Epoch: 053 cost function= 0.2360200  Validation Error: 0.07059997320175171\n",
      "Epoch: 054 cost function= 0.2357276  Validation Error: 0.06940001249313354\n",
      "Epoch: 055 cost function= 0.2351787  Validation Error: 0.07200002670288086\n",
      "Epoch: 056 cost function= 0.2348244  Validation Error: 0.06940001249313354\n",
      "Epoch: 057 cost function= 0.2348746  Validation Error: 0.07020002603530884\n",
      "Epoch: 058 cost function= 0.2345481  Validation Error: 0.06999999284744263\n",
      "Epoch: 059 cost function= 0.2340743  Validation Error: 0.07039999961853027\n",
      "Epoch: 060 cost function= 0.2337651  Validation Error: 0.07020002603530884\n",
      "Epoch: 061 cost function= 0.2336891  Validation Error: 0.06999999284744263\n",
      "Epoch: 062 cost function= 0.2333766  Validation Error: 0.06840002536773682\n",
      "Epoch: 063 cost function= 0.2331728  Validation Error: 0.06840002536773682\n",
      "Epoch: 064 cost function= 0.2327767  Validation Error: 0.07039999961853027\n",
      "Epoch: 065 cost function= 0.2326737  Validation Error: 0.06999999284744263\n",
      "Epoch: 066 cost function= 0.2325025  Validation Error: 0.07039999961853027\n",
      "Epoch: 067 cost function= 0.2320863  Validation Error: 0.06859999895095825\n",
      "Epoch: 068 cost function= 0.2320997  Validation Error: 0.07059997320175171\n",
      "Epoch: 069 cost function= 0.2317378  Validation Error: 0.06940001249313354\n",
      "Epoch: 070 cost function= 0.2313381  Validation Error: 0.07160001993179321\n",
      "Epoch: 071 cost function= 0.2312528  Validation Error: 0.07099997997283936\n",
      "Epoch: 072 cost function= 0.2311422  Validation Error: 0.07099997997283936\n",
      "Epoch: 073 cost function= 0.2307765  Validation Error: 0.07039999961853027\n",
      "Epoch: 074 cost function= 0.2307389  Validation Error: 0.07120001316070557\n",
      "Epoch: 075 cost function= 0.2304142  Validation Error: 0.06879997253417969\n",
      "Epoch: 076 cost function= 0.2299368  Validation Error: 0.06999999284744263\n",
      "Epoch: 077 cost function= 0.2301693  Validation Error: 0.07080000638961792\n",
      "Epoch: 078 cost function= 0.2298719  Validation Error: 0.07120001316070557\n",
      "Epoch: 079 cost function= 0.2296948  Validation Error: 0.0722000002861023\n",
      "Epoch: 080 cost function= 0.2295357  Validation Error: 0.071399986743927\n",
      "Epoch: 081 cost function= 0.2293988  Validation Error: 0.07059997320175171\n",
      "Epoch: 082 cost function= 0.2290983  Validation Error: 0.07160001993179321\n",
      "Epoch: 083 cost function= 0.2290424  Validation Error: 0.07260000705718994\n",
      "Epoch: 084 cost function= 0.2288500  Validation Error: 0.071399986743927\n",
      "Epoch: 085 cost function= 0.2285257  Validation Error: 0.07039999961853027\n",
      "Epoch: 086 cost function= 0.2283286  Validation Error: 0.06980001926422119\n",
      "Epoch: 087 cost function= 0.2281008  Validation Error: 0.071399986743927\n",
      "Epoch: 088 cost function= 0.2281928  Validation Error: 0.0681999921798706\n",
      "Epoch: 089 cost function= 0.2278641  Validation Error: 0.071399986743927\n",
      "Epoch: 090 cost function= 0.2277972  Validation Error: 0.07179999351501465\n",
      "Epoch: 091 cost function= 0.2275558  Validation Error: 0.06999999284744263\n",
      "Epoch: 092 cost function= 0.2276652  Validation Error: 0.06999999284744263\n",
      "Epoch: 093 cost function= 0.2274863  Validation Error: 0.07120001316070557\n",
      "Epoch: 094 cost function= 0.2270033  Validation Error: 0.0722000002861023\n",
      "Epoch: 095 cost function= 0.2271693  Validation Error: 0.06940001249313354\n",
      "Epoch: 096 cost function= 0.2267457  Validation Error: 0.071399986743927\n",
      "Epoch: 097 cost function= 0.2267178  Validation Error: 0.06840002536773682\n",
      "Epoch: 098 cost function= 0.2266968  Validation Error: 0.07020002603530884\n",
      "Epoch: 099 cost function= 0.2263057  Validation Error: 0.07039999961853027\n",
      "Epoch: 100 cost function= 0.2263622  Validation Error: 0.07200002670288086\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.9285\n",
      "Execution time was 92.793\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #change it with your own path\n",
    "    log_files_path = 'C:/Users/Ali/logs/no_layer_2/'\n",
    "    #log_files_path = 'C:/Users/Ali/Google Drive/CoursesColumbiaUniveristy/DeepLearning/codes/week3/logs/no_layer/'\n",
    "\n",
    "    # read \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/Graph\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "            \n",
    "        # first build the structure of our neural network\n",
    "\n",
    "        # variables has to be set up as placeholder before importing data\n",
    "        x = tf.placeholder(\"float\", [None, 784]) # MNIST data image of shape 28*28=784\n",
    "\n",
    "        # y is the label in one-hot-encoding format\n",
    "        y = tf.placeholder(\"float\", [None, 10])  # 0-9 digits recognition\n",
    "\n",
    "        #output is a matrix of probabilities\n",
    "        output = inference(x)\n",
    "\n",
    "        cost = loss(output, y)\n",
    "        # set the initial value of global_step as 0\n",
    "        # this will increase by 1 every time weights are updated\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        train_op = training(cost, global_step)\n",
    "        #train_op = training(cost, global_step=None)\n",
    "\n",
    "        eval_op = evaluate(output, y)\n",
    "\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "        saver = tf.train.Saver()\n",
    "        #define a session\n",
    "        sess = tf.Session()\n",
    "\n",
    "        # needed for saving the graph\n",
    "        summary_writer = tf.summary.FileWriter(log_files_path, sess.graph)\n",
    "\n",
    "        #all variables need to be initialized by sess.run(tf.global_variables_initializer())\n",
    "        init_op = tf.global_variables_initializer()\n",
    "\n",
    "        sess.run(init_op)\n",
    "\n",
    "        print('mnist.train.num_examples ', mnist.train.num_examples)\n",
    "        print('mnist.test.num_examples ', mnist.test.num_examples)\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(mnist.train.num_examples/batch_size)\n",
    "            #print('total_batch ', total_batch)\n",
    "\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "\n",
    "                minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                \n",
    "                # Fit training using batch data\n",
    "                # Weights are only updated when we run the optimizer\n",
    "                sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                \n",
    "                # Compute average loss\n",
    "                avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
    "\n",
    "            # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "                \n",
    "                # Get the accuracy by running the eval_op with validation sets of data\n",
    "                accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "\n",
    "                print(\"Epoch:\", '%03d' % (epoch+1), \"cost function=\", \"{:0.7f}\".format(avg_cost), \" Validation Error:\", (1.0 - accuracy))\n",
    "\n",
    "                summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
    "                summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "\n",
    "                #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Check the final accuracy after training\n",
    "        accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print('Execution time was %0.3f' % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
